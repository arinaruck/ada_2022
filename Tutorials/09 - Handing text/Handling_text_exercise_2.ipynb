{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from helpers.helper_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling text 2 exercise\n",
    "[Handling text exercisses ADApted drom ADA 2018 final exam]\n",
    "\n",
    "The Sheldon Cooper we all know and love (OK, some of us might not know him, and some might not love him) from the TV series \"The Big Bang Theory\" has gotten into an argument with Leonard from the same TV show. Sheldon insists that he knows the show better than anyone, and keeps making various claims about the show, which neither of them know how to prove or disprove. The two of them have reached out to you ladies and gentlemen, as data scientists, to help them. You will be given the full script of the series, with information on the episode, the scene, the person saying each dialogue line, and the dialogue lines themselves.\n",
    "\n",
    "Leonard has challenged several of Sheldon's claims about the show, and throughout this exam you will see some of those and you will get to prove or disprove them, but remember: sometimes, we can neither prove a claim, nor disprove it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task A: Picking up the shovel\n",
    "\n",
    "**Note: You will use the data you preprocess in this task in all the subsequent ones.**\n",
    "\n",
    "Our friends' argument concerns the entire show. We have given you a file in the `data/` folder that contains the script of every single episode. New episodes are indicated by '>>', new scenes by '>', and the rest of the lines are dialogue lines. Some lines are said by multiple people (for example, lines indicated by 'All' or 'Together'); **you must discard these lines**, for the sake of simplicity. However, you do not need to do it for Q1 in this task -- you'll take care of it when you solve Q2.\n",
    "\n",
    "**Q1**. Your first task is to extract all lines of dialogue in each scene and episode, creating a dataframe where each row has the episode and scene where a dialogue line was said, the character who said it, and the line itself. You do not need to extract the proper name of the episode (e.g. episode 1 can appear as \"Series 01 Episode 01 - Pilot Episode\", and doesn't need to appear as \"Pilot Episode\"). Then, answer the following question: In total, how many scenes are there in each season? We're not asking about unique scenes; the same location appearing in two episodes counts as two scenes. You can use a Pandas dataframe with a season column and a scene count column as the response.\n",
    "\n",
    "**Note: The data refers to seasons as \"series\".**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "data_path = Path('data/all_scripts.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Series 01 Episode 01 – Pilot Episode\n",
      "> A corridor at a sperm bank.\n",
      "Sheldon: So if a photon is directed through a plane with two slits in it and either slit is observed it will not go through both slits. If it’s unobserved it will, however, if it’s observed after it’s left the plane but before it hits its target, it will not have gone through both slits.\n",
      "Leonard: Agreed, what’s your point?\n",
      "Sheldon: There’s no point, I just think it’s a good idea for a tee-shirt.\n",
      "Leonard: Excuse me?\n",
      "Receptionist: Hang on.\n",
      "Leonard: One across is Aegean, eight down is Nabakov, twenty-six across is MCM, fourteen down is… move your finger… phylum, which makes fourteen across Port-au-Prince. See, Papa Doc’s capital idea, that’s Port-au-Prince. Haiti.\n",
      "Receptionist: Can I help you?\n",
      "Leonard: Yes. Um, is this the High IQ sperm bank?\n"
     ]
    }
   ],
   "source": [
    "!head data/all_scripts.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "with open(data_path, 'r') as f:\n",
    "    all_lines = f.read()\n",
    "    episodes = all_lines.split('>> ')\n",
    "    # removing first empty episode\n",
    "    episodes = episodes[1:]\n",
    "    episode_to_scenes = {}\n",
    "    for episode in episodes:\n",
    "        scenes = episode.split('> ')\n",
    "        episode_info, scenes = scenes[0], scenes[1:]\n",
    "        res = re.match(r'(?P<season>Series \\d{2}) (?P<episode>Episode \\d{2}) – (?P<title>.*)', episode_info.strip())\n",
    "        season, episode_number, episode_title = res.group('season'), res.group('episode'), res.group('title')\n",
    "        for i, scene in enumerate(scenes):\n",
    "            scene_setting, lines = scene.split('\\n', 1)\n",
    "            for line in lines.strip().split('\\n'):\n",
    "                character, replica = line.split(': ', 1)\n",
    "                line_description = {'season': season, 'episode_number': episode_number, \\\n",
    "                                    'episode_title': episode_title, 'scene_setting': scene_setting.strip(), 'scene_n': i + 1, \\\n",
    "                                    'character': character.strip(), 'line': replica.strip(), \\\n",
    "                                    }\n",
    "                data.append(line_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>episode_number</th>\n",
       "      <th>episode_title</th>\n",
       "      <th>scene_setting</th>\n",
       "      <th>scene_n</th>\n",
       "      <th>character</th>\n",
       "      <th>line</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Series 01</td>\n",
       "      <td>Episode 01</td>\n",
       "      <td>Pilot Episode</td>\n",
       "      <td>A corridor at a sperm bank.</td>\n",
       "      <td>1</td>\n",
       "      <td>Sheldon</td>\n",
       "      <td>So if a photon is directed through a plane wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Series 01</td>\n",
       "      <td>Episode 01</td>\n",
       "      <td>Pilot Episode</td>\n",
       "      <td>A corridor at a sperm bank.</td>\n",
       "      <td>1</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>Agreed, what’s your point?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Series 01</td>\n",
       "      <td>Episode 01</td>\n",
       "      <td>Pilot Episode</td>\n",
       "      <td>A corridor at a sperm bank.</td>\n",
       "      <td>1</td>\n",
       "      <td>Sheldon</td>\n",
       "      <td>There’s no point, I just think it’s a good ide...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Series 01</td>\n",
       "      <td>Episode 01</td>\n",
       "      <td>Pilot Episode</td>\n",
       "      <td>A corridor at a sperm bank.</td>\n",
       "      <td>1</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>Excuse me?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Series 01</td>\n",
       "      <td>Episode 01</td>\n",
       "      <td>Pilot Episode</td>\n",
       "      <td>A corridor at a sperm bank.</td>\n",
       "      <td>1</td>\n",
       "      <td>Receptionist</td>\n",
       "      <td>Hang on.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      season episode_number  episode_title                scene_setting  \\\n",
       "0  Series 01     Episode 01  Pilot Episode  A corridor at a sperm bank.   \n",
       "1  Series 01     Episode 01  Pilot Episode  A corridor at a sperm bank.   \n",
       "2  Series 01     Episode 01  Pilot Episode  A corridor at a sperm bank.   \n",
       "3  Series 01     Episode 01  Pilot Episode  A corridor at a sperm bank.   \n",
       "4  Series 01     Episode 01  Pilot Episode  A corridor at a sperm bank.   \n",
       "\n",
       "   scene_n     character                                               line  \n",
       "0        1       Sheldon  So if a photon is directed through a plane wit...  \n",
       "1        1       Leonard                         Agreed, what’s your point?  \n",
       "2        1       Sheldon  There’s no point, I just think it’s a good ide...  \n",
       "3        1       Leonard                                         Excuse me?  \n",
       "4        1  Receptionist                                           Hang on.  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replicas_df = pd.DataFrame(data=data)\n",
    "replicas_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scene_n</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>season</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Series 01</th>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Series 02</th>\n",
       "      <td>231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Series 03</th>\n",
       "      <td>236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Series 04</th>\n",
       "      <td>279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Series 05</th>\n",
       "      <td>254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Series 06</th>\n",
       "      <td>304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Series 07</th>\n",
       "      <td>332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Series 08</th>\n",
       "      <td>328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Series 09</th>\n",
       "      <td>337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Series 10</th>\n",
       "      <td>347</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           scene_n\n",
       "season            \n",
       "Series 01      160\n",
       "Series 02      231\n",
       "Series 03      236\n",
       "Series 04      279\n",
       "Series 05      254\n",
       "Series 06      304\n",
       "Series 07      332\n",
       "Series 08      328\n",
       "Series 09      337\n",
       "Series 10      347"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scenes_in_episodes = replicas_df[['season', 'episode_number', 'scene_n']].groupby(['season', 'episode_number']).max().reset_index()\n",
    "scenes_in_seasons = scenes_in_episodes[['season', 'scene_n']].groupby('season').sum()\n",
    "scenes_in_seasons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2**. Now, let's define two sets of characters: all the characters, and recurrent characters. Recurrent characters are those who appear in more than one episode. For the subsequent sections, you will need to have a list of recurrent characters. Assume that there are no two _named characters_ (i.e. characters who have actual names and aren't referred to generically as \"little girl\", \"grumpy grandpa\", etc.) with the same name, i.e. there are no two Sheldons, etc. Generate a list of recurrent characters who have more than 90 dialogue lines in total, and then take a look at the list you have. If you've done this correctly, you should have a list of 20 names. However, one of these is clearly not a recurrent character. Manually remove that one, and print out your list of recurrent characters. To remove that character, pay attention to the _named character_ assumption we gave you earlier on. **For all the subsequent questions, you must only keep the dialogue lines said by the recurrent characters in your list.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sheldon', 'Leonard', 'Penny', 'Howard', 'Raj', 'Man', 'Mrs Cooper', 'Leslie', 'Kripke', 'Beverley', 'Stuart', 'Bernadette', 'Wil', 'Mrs Wolowitz', 'Zack', 'Amy', 'Priya', 'Arthur', 'Bert', 'Emily'] 20\n"
     ]
    }
   ],
   "source": [
    "filtered_replicas = replicas_df.groupby('character').filter(lambda row: row['episode_title'].nunique() > 1 and row['line'].count() > 90)\n",
    "recurrent_characters  = filtered_replicas.character.unique().tolist()\n",
    "print(recurrent_characters, len(recurrent_characters))\n",
    "recurrent_characters.remove('Man')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>episode_number</th>\n",
       "      <th>episode_title</th>\n",
       "      <th>scene_setting</th>\n",
       "      <th>scene_n</th>\n",
       "      <th>character</th>\n",
       "      <th>line</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Series 01</td>\n",
       "      <td>Episode 01</td>\n",
       "      <td>Pilot Episode</td>\n",
       "      <td>A corridor at a sperm bank.</td>\n",
       "      <td>1</td>\n",
       "      <td>Sheldon</td>\n",
       "      <td>So if a photon is directed through a plane wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Series 01</td>\n",
       "      <td>Episode 01</td>\n",
       "      <td>Pilot Episode</td>\n",
       "      <td>A corridor at a sperm bank.</td>\n",
       "      <td>1</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>Agreed, what’s your point?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Series 01</td>\n",
       "      <td>Episode 01</td>\n",
       "      <td>Pilot Episode</td>\n",
       "      <td>A corridor at a sperm bank.</td>\n",
       "      <td>1</td>\n",
       "      <td>Sheldon</td>\n",
       "      <td>There’s no point, I just think it’s a good ide...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Series 01</td>\n",
       "      <td>Episode 01</td>\n",
       "      <td>Pilot Episode</td>\n",
       "      <td>A corridor at a sperm bank.</td>\n",
       "      <td>1</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>Excuse me?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Series 01</td>\n",
       "      <td>Episode 01</td>\n",
       "      <td>Pilot Episode</td>\n",
       "      <td>A corridor at a sperm bank.</td>\n",
       "      <td>1</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>One across is Aegean, eight down is Nabakov, t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      season episode_number  episode_title                scene_setting  \\\n",
       "0  Series 01     Episode 01  Pilot Episode  A corridor at a sperm bank.   \n",
       "1  Series 01     Episode 01  Pilot Episode  A corridor at a sperm bank.   \n",
       "2  Series 01     Episode 01  Pilot Episode  A corridor at a sperm bank.   \n",
       "3  Series 01     Episode 01  Pilot Episode  A corridor at a sperm bank.   \n",
       "5  Series 01     Episode 01  Pilot Episode  A corridor at a sperm bank.   \n",
       "\n",
       "   scene_n character                                               line  \n",
       "0        1   Sheldon  So if a photon is directed through a plane wit...  \n",
       "1        1   Leonard                         Agreed, what’s your point?  \n",
       "2        1   Sheldon  There’s no point, I just think it’s a good ide...  \n",
       "3        1   Leonard                                         Excuse me?  \n",
       "5        1   Leonard  One across is Aegean, eight down is Nabakov, t...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df = replicas_df[replicas_df.character.isin(recurrent_characters)]\n",
    "filtered_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task B: Read the scripts carefully\n",
    "\n",
    "### Part 1: Don't put the shovel down just yet\n",
    "\n",
    "**Q3**. From each dialogue line, replace punctuation marks (listed in the EXCLUDE_CHARS variable provided in `helpers/helper_functions.py`) with whitespaces, and lowercase all the text. **Do not remove any stopwords, leave them be for all the questions in this task.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\\)`@\\}\\-<;\\*_\"!\\]\\{'>=\\#\\$\\|%\\?\\(,\\^\\.\\~/\\&\\+:’\\\\\\[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9t/5ml_m_x53vs0ydn7wx7l76l80000gn/T/ipykernel_62617/955731200.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['cleaned_line'] = filtered_df.line.str.replace(punct, ' ').str.lower()\n"
     ]
    }
   ],
   "source": [
    "from helpers.helper_functions import EXCLUDE_CHARS\n",
    "\n",
    "print(fr'[{re.escape(\"\".join(EXCLUDE_CHARS))}]')\n",
    "punct = re.compile(fr'[{re.escape(\"\".join(EXCLUDE_CHARS))}]')\n",
    "filtered_df['cleaned_line'] = filtered_df.line.str.replace(punct, ' ').str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>episode_number</th>\n",
       "      <th>episode_title</th>\n",
       "      <th>scene_setting</th>\n",
       "      <th>scene_n</th>\n",
       "      <th>character</th>\n",
       "      <th>line</th>\n",
       "      <th>cleaned_line</th>\n",
       "      <th>tokens</th>\n",
       "      <th>n_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Series 01</td>\n",
       "      <td>Episode 01</td>\n",
       "      <td>Pilot Episode</td>\n",
       "      <td>A corridor at a sperm bank.</td>\n",
       "      <td>1</td>\n",
       "      <td>Sheldon</td>\n",
       "      <td>So if a photon is directed through a plane wit...</td>\n",
       "      <td>so if a photon is directed through a plane wit...</td>\n",
       "      <td>[so, if, a, photon, is, directed, through, a, ...</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Series 01</td>\n",
       "      <td>Episode 01</td>\n",
       "      <td>Pilot Episode</td>\n",
       "      <td>A corridor at a sperm bank.</td>\n",
       "      <td>1</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>Agreed, what’s your point?</td>\n",
       "      <td>agreed  what s your point</td>\n",
       "      <td>[agreed, what, s, your, point, ]</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Series 01</td>\n",
       "      <td>Episode 01</td>\n",
       "      <td>Pilot Episode</td>\n",
       "      <td>A corridor at a sperm bank.</td>\n",
       "      <td>1</td>\n",
       "      <td>Sheldon</td>\n",
       "      <td>There’s no point, I just think it’s a good ide...</td>\n",
       "      <td>there s no point  i just think it s a good ide...</td>\n",
       "      <td>[there, s, no, point, i, just, think, it, s, a...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Series 01</td>\n",
       "      <td>Episode 01</td>\n",
       "      <td>Pilot Episode</td>\n",
       "      <td>A corridor at a sperm bank.</td>\n",
       "      <td>1</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>Excuse me?</td>\n",
       "      <td>excuse me</td>\n",
       "      <td>[excuse, me, ]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Series 01</td>\n",
       "      <td>Episode 01</td>\n",
       "      <td>Pilot Episode</td>\n",
       "      <td>A corridor at a sperm bank.</td>\n",
       "      <td>1</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>One across is Aegean, eight down is Nabakov, t...</td>\n",
       "      <td>one across is aegean  eight down is nabakov  t...</td>\n",
       "      <td>[one, across, is, aegean, eight, down, is, nab...</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51284</th>\n",
       "      <td>Series 10</td>\n",
       "      <td>Episode 24</td>\n",
       "      <td>The Long Distance Dissonance</td>\n",
       "      <td>Sheldon’s office.</td>\n",
       "      <td>14</td>\n",
       "      <td>Sheldon</td>\n",
       "      <td>Uh, breakfast yes, lunch no. I did have a coug...</td>\n",
       "      <td>uh  breakfast yes  lunch no  i did have a coug...</td>\n",
       "      <td>[uh, breakfast, yes, lunch, no, i, did, have, ...</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51286</th>\n",
       "      <td>Series 10</td>\n",
       "      <td>Episode 24</td>\n",
       "      <td>The Long Distance Dissonance</td>\n",
       "      <td>Sheldon’s office.</td>\n",
       "      <td>14</td>\n",
       "      <td>Sheldon</td>\n",
       "      <td>How thoughtful. Thank you.</td>\n",
       "      <td>how thoughtful  thank you</td>\n",
       "      <td>[how, thoughtful, thank, you, ]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51288</th>\n",
       "      <td>Series 10</td>\n",
       "      <td>Episode 24</td>\n",
       "      <td>The Long Distance Dissonance</td>\n",
       "      <td>Sheldon’s office.</td>\n",
       "      <td>14</td>\n",
       "      <td>Sheldon</td>\n",
       "      <td>And I with you. Question, are you seeking a ro...</td>\n",
       "      <td>and i with you  question  are you seeking a ro...</td>\n",
       "      <td>[and, i, with, you, question, are, you, seekin...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51290</th>\n",
       "      <td>Series 10</td>\n",
       "      <td>Episode 24</td>\n",
       "      <td>The Long Distance Dissonance</td>\n",
       "      <td>Sheldon’s office.</td>\n",
       "      <td>14</td>\n",
       "      <td>Sheldon</td>\n",
       "      <td>Well, that would raise a number of problems. W...</td>\n",
       "      <td>well  that would raise a number of problems  w...</td>\n",
       "      <td>[well, that, would, raise, a, number, of, prob...</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51291</th>\n",
       "      <td>Series 10</td>\n",
       "      <td>Episode 24</td>\n",
       "      <td>The Long Distance Dissonance</td>\n",
       "      <td>Princeton.</td>\n",
       "      <td>15</td>\n",
       "      <td>Sheldon</td>\n",
       "      <td>(Knock, knock, knock) Amy. (Knock, knock, knoc...</td>\n",
       "      <td>knock  knock  knock  amy   knock  knock  knoc...</td>\n",
       "      <td>[, knock, knock, knock, amy, knock, knock, kno...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48346 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          season episode_number                 episode_title  \\\n",
       "0      Series 01     Episode 01                 Pilot Episode   \n",
       "1      Series 01     Episode 01                 Pilot Episode   \n",
       "2      Series 01     Episode 01                 Pilot Episode   \n",
       "3      Series 01     Episode 01                 Pilot Episode   \n",
       "5      Series 01     Episode 01                 Pilot Episode   \n",
       "...          ...            ...                           ...   \n",
       "51284  Series 10     Episode 24  The Long Distance Dissonance   \n",
       "51286  Series 10     Episode 24  The Long Distance Dissonance   \n",
       "51288  Series 10     Episode 24  The Long Distance Dissonance   \n",
       "51290  Series 10     Episode 24  The Long Distance Dissonance   \n",
       "51291  Series 10     Episode 24  The Long Distance Dissonance   \n",
       "\n",
       "                     scene_setting  scene_n character  \\\n",
       "0      A corridor at a sperm bank.        1   Sheldon   \n",
       "1      A corridor at a sperm bank.        1   Leonard   \n",
       "2      A corridor at a sperm bank.        1   Sheldon   \n",
       "3      A corridor at a sperm bank.        1   Leonard   \n",
       "5      A corridor at a sperm bank.        1   Leonard   \n",
       "...                            ...      ...       ...   \n",
       "51284            Sheldon’s office.       14   Sheldon   \n",
       "51286            Sheldon’s office.       14   Sheldon   \n",
       "51288            Sheldon’s office.       14   Sheldon   \n",
       "51290            Sheldon’s office.       14   Sheldon   \n",
       "51291                   Princeton.       15   Sheldon   \n",
       "\n",
       "                                                    line  \\\n",
       "0      So if a photon is directed through a plane wit...   \n",
       "1                             Agreed, what’s your point?   \n",
       "2      There’s no point, I just think it’s a good ide...   \n",
       "3                                             Excuse me?   \n",
       "5      One across is Aegean, eight down is Nabakov, t...   \n",
       "...                                                  ...   \n",
       "51284  Uh, breakfast yes, lunch no. I did have a coug...   \n",
       "51286                         How thoughtful. Thank you.   \n",
       "51288  And I with you. Question, are you seeking a ro...   \n",
       "51290  Well, that would raise a number of problems. W...   \n",
       "51291  (Knock, knock, knock) Amy. (Knock, knock, knoc...   \n",
       "\n",
       "                                            cleaned_line  \\\n",
       "0      so if a photon is directed through a plane wit...   \n",
       "1                             agreed  what s your point    \n",
       "2      there s no point  i just think it s a good ide...   \n",
       "3                                             excuse me    \n",
       "5      one across is aegean  eight down is nabakov  t...   \n",
       "...                                                  ...   \n",
       "51284  uh  breakfast yes  lunch no  i did have a coug...   \n",
       "51286                         how thoughtful  thank you    \n",
       "51288  and i with you  question  are you seeking a ro...   \n",
       "51290  well  that would raise a number of problems  w...   \n",
       "51291   knock  knock  knock  amy   knock  knock  knoc...   \n",
       "\n",
       "                                                  tokens  n_tokens  \n",
       "0      [so, if, a, photon, is, directed, through, a, ...        58  \n",
       "1                       [agreed, what, s, your, point, ]         6  \n",
       "2      [there, s, no, point, i, just, think, it, s, a...        17  \n",
       "3                                         [excuse, me, ]         3  \n",
       "5      [one, across, is, aegean, eight, down, is, nab...        40  \n",
       "...                                                  ...       ...  \n",
       "51284  [uh, breakfast, yes, lunch, no, i, did, have, ...        22  \n",
       "51286                    [how, thoughtful, thank, you, ]         5  \n",
       "51288  [and, i, with, you, question, are, you, seekin...        14  \n",
       "51290  [well, that, would, raise, a, number, of, prob...        22  \n",
       "51291  [, knock, knock, knock, amy, knock, knock, kno...        18  \n",
       "\n",
       "[48346 rows x 10 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q4**. For each term, calculate its \"corpus frequency\", i.e. its number of occurrences in the entire series. Visualize the distribution of corpus frequency using a histogram. Explain your observations. What are the appropriate x and y scales for this plot?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "corpus = ' '.join(filtered_df.cleaned_line.values.tolist())\n",
    "words = [token for token in re.split(r'\\s+', corpus)]\n",
    "\n",
    "# five most common tokens\n",
    "word_freq = Counter(words)\n",
    "freq_list = sorted(list(word_freq.values()))[::-1]\n",
    "plt.hist(word_freq.keys(), weights=word_freq.values(), label=\"term frequency\")\n",
    "plt.yscale('log')\n",
    "plt.xticks([], []);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Talkativity\n",
    "**Q5**. For each of the recurrent characters, calculate their total number of words uttered across all episodes. Based on this, who seems to be the most talkative character?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9t/5ml_m_x53vs0ydn7wx7l76l80000gn/T/ipykernel_62617/1667759469.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df.loc[:, 'tokens'] = filtered_df.cleaned_line.str.strip().str.split(r'\\s+', regex=True)\n",
      "/var/folders/9t/5ml_m_x53vs0ydn7wx7l76l80000gn/T/ipykernel_62617/1667759469.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df.loc[:, 'n_tokens'] = filtered_df.tokens.str.len()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "character\n",
       "Sheldon         185388\n",
       "Leonard         102496\n",
       "Penny            79271\n",
       "Howard           69505\n",
       "Raj              60099\n",
       "Amy              39929\n",
       "Bernadette       27724\n",
       "Stuart            7955\n",
       "Mrs Cooper        3389\n",
       "Beverley          2029\n",
       "Priya             1940\n",
       "Wil               1678\n",
       "Emily             1571\n",
       "Mrs Wolowitz      1459\n",
       "Arthur            1451\n",
       "Zack              1427\n",
       "Leslie            1249\n",
       "Kripke            1246\n",
       "Bert              1146\n",
       "Name: n_tokens, dtype: int64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df.loc[:, 'tokens'] = filtered_df.cleaned_line.str.strip().str.split(r'\\s+', regex=True)\n",
    "filtered_df.loc[:, 'n_tokens'] = filtered_df.tokens.str.len()\n",
    "\n",
    "character_talkativity = filtered_df.groupby('character').n_tokens.sum().sort_values(ascending=False)\n",
    "character_talkativity "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task D: The Detective's Hat\n",
    "\n",
    "Sheldon claims that given a dialogue line, he can, with an accuracy of above 70%, say whether it's by himself or by someone else. Leonard contests this claim, since he believes that this claimed accuracy is too high.\n",
    "\n",
    "**Q6**. Divide the set of all dialogue lines into two subsets: the training set, consisting of all the seasons except the last two, and the test set, consisting of the last two seasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "replicas_df.loc[:, 'cleaned_line'] = replicas_df.line.str.replace(punct, ' ').str.lower()\n",
    "replicas_df.loc[:, 'tokens'] = replicas_df.cleaned_line.str.strip().str.split(r'\\s+', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_seasons = ['Series 09', 'Series 10']\n",
    "train_df = replicas_df[~replicas_df.season.isin(test_seasons)]\n",
    "test_df = replicas_df[replicas_df.season.isin(test_seasons)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q7**. Find the set of all words in the training set that are only uttered by Sheldon. Is it possible for Sheldon to identify himself only based on these? Use the test set to assess this possibility, and explain your method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non sheldon tokens: 14928, sheldon tokens: 13134\n",
      "Only sheldon tokens: 5066\n"
     ]
    }
   ],
   "source": [
    "non_sheldon_tokens = set()\n",
    "sheldon_tokens = set()\n",
    "for tokens in train_df[train_df.character != 'Sheldon'].tokens.values.tolist():\n",
    "    non_sheldon_tokens.update(tokens)\n",
    "\n",
    "for tokens in train_df[train_df.character == 'Sheldon'].tokens.values.tolist():\n",
    "    sheldon_tokens.update(tokens)\n",
    "\n",
    "print(f'Non sheldon tokens: {len(non_sheldon_tokens)}, sheldon tokens: {len(sheldon_tokens)}')\n",
    "\n",
    "only_sheldon_tokens = sheldon_tokens - non_sheldon_tokens\n",
    "print(f'Only sheldon tokens: {len(only_sheldon_tokens)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['destined', 'testament', 'astonishing', 'oppressors', 'minded', 'horoscopes', 'nameless', 'pinata', 'horribly', 'inexact']\n"
     ]
    }
   ],
   "source": [
    "print(list(only_sheldon_tokens)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9t/5ml_m_x53vs0ydn7wx7l76l80000gn/T/ipykernel_62617/794080814.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['pred_Sheldon'] = test_df.tokens.apply(is_Sheldon)\n",
      "/var/folders/9t/5ml_m_x53vs0ydn7wx7l76l80000gn/T/ipykernel_62617/794080814.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['pred_Sheldon'] = test_df.pred_Sheldon.map({True: 'Sheldon', False: 'Other'})\n",
      "/var/folders/9t/5ml_m_x53vs0ydn7wx7l76l80000gn/T/ipykernel_62617/794080814.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['true_Sheldon'] = test_df.character.map(lambda x: 'Sheldon' if x == 'Sheldon' else 'Other')\n"
     ]
    }
   ],
   "source": [
    "def is_Sheldon(tokens):\n",
    "    return len(set(tokens) & only_sheldon_tokens) > 0\n",
    "\n",
    "test_df['pred_Sheldon'] = test_df.tokens.apply(is_Sheldon)\n",
    "test_df['pred_Sheldon'] = test_df.pred_Sheldon.map({True: 'Sheldon', False: 'Other'})\n",
    "test_df['true_Sheldon'] = test_df.character.map(lambda x: 'Sheldon' if x == 'Sheldon' else 'Other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>episode_number</th>\n",
       "      <th>episode_title</th>\n",
       "      <th>scene_setting</th>\n",
       "      <th>scene_n</th>\n",
       "      <th>character</th>\n",
       "      <th>line</th>\n",
       "      <th>cleaned_line</th>\n",
       "      <th>tokens</th>\n",
       "      <th>pred_Sheldon</th>\n",
       "      <th>true_Sheldon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40354</th>\n",
       "      <td>Series 09</td>\n",
       "      <td>Episode 01</td>\n",
       "      <td>The Matrimonial Momentum</td>\n",
       "      <td>A Wedding Chapel.</td>\n",
       "      <td>1</td>\n",
       "      <td>Penny</td>\n",
       "      <td>So, what package are you thinking?</td>\n",
       "      <td>so  what package are you thinking</td>\n",
       "      <td>[so, what, package, are, you, thinking]</td>\n",
       "      <td>Other</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40355</th>\n",
       "      <td>Series 09</td>\n",
       "      <td>Episode 01</td>\n",
       "      <td>The Matrimonial Momentum</td>\n",
       "      <td>A Wedding Chapel.</td>\n",
       "      <td>1</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>Mm, this one comes with music and flowers. Oh,...</td>\n",
       "      <td>mm  this one comes with music and flowers  oh ...</td>\n",
       "      <td>[mm, this, one, comes, with, music, and, flowe...</td>\n",
       "      <td>Other</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40356</th>\n",
       "      <td>Series 09</td>\n",
       "      <td>Episode 01</td>\n",
       "      <td>The Matrimonial Momentum</td>\n",
       "      <td>A Wedding Chapel.</td>\n",
       "      <td>1</td>\n",
       "      <td>Penny</td>\n",
       "      <td>Why would we want that?</td>\n",
       "      <td>why would we want that</td>\n",
       "      <td>[why, would, we, want, that]</td>\n",
       "      <td>Other</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40357</th>\n",
       "      <td>Series 09</td>\n",
       "      <td>Episode 01</td>\n",
       "      <td>The Matrimonial Momentum</td>\n",
       "      <td>A Wedding Chapel.</td>\n",
       "      <td>1</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>‘Cause there’s a lot of gorgeous blondes out t...</td>\n",
       "      <td>‘cause there s a lot of gorgeous blondes out t...</td>\n",
       "      <td>[‘cause, there, s, a, lot, of, gorgeous, blond...</td>\n",
       "      <td>Other</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40358</th>\n",
       "      <td>Series 09</td>\n",
       "      <td>Episode 01</td>\n",
       "      <td>The Matrimonial Momentum</td>\n",
       "      <td>A Wedding Chapel.</td>\n",
       "      <td>1</td>\n",
       "      <td>Penny</td>\n",
       "      <td>Whatever. Put us on the Internet. I’ve always ...</td>\n",
       "      <td>whatever  put us on the internet  i ve always ...</td>\n",
       "      <td>[whatever, put, us, on, the, internet, i, ve, ...</td>\n",
       "      <td>Other</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          season episode_number             episode_title      scene_setting  \\\n",
       "40354  Series 09     Episode 01  The Matrimonial Momentum  A Wedding Chapel.   \n",
       "40355  Series 09     Episode 01  The Matrimonial Momentum  A Wedding Chapel.   \n",
       "40356  Series 09     Episode 01  The Matrimonial Momentum  A Wedding Chapel.   \n",
       "40357  Series 09     Episode 01  The Matrimonial Momentum  A Wedding Chapel.   \n",
       "40358  Series 09     Episode 01  The Matrimonial Momentum  A Wedding Chapel.   \n",
       "\n",
       "       scene_n character                                               line  \\\n",
       "40354        1     Penny                 So, what package are you thinking?   \n",
       "40355        1   Leonard  Mm, this one comes with music and flowers. Oh,...   \n",
       "40356        1     Penny                            Why would we want that?   \n",
       "40357        1   Leonard  ‘Cause there’s a lot of gorgeous blondes out t...   \n",
       "40358        1     Penny  Whatever. Put us on the Internet. I’ve always ...   \n",
       "\n",
       "                                            cleaned_line  \\\n",
       "40354                 so  what package are you thinking    \n",
       "40355  mm  this one comes with music and flowers  oh ...   \n",
       "40356                            why would we want that    \n",
       "40357  ‘cause there s a lot of gorgeous blondes out t...   \n",
       "40358  whatever  put us on the internet  i ve always ...   \n",
       "\n",
       "                                                  tokens pred_Sheldon  \\\n",
       "40354            [so, what, package, are, you, thinking]        Other   \n",
       "40355  [mm, this, one, comes, with, music, and, flowe...        Other   \n",
       "40356                       [why, would, we, want, that]        Other   \n",
       "40357  [‘cause, there, s, a, lot, of, gorgeous, blond...        Other   \n",
       "40358  [whatever, put, us, on, the, internet, i, ve, ...        Other   \n",
       "\n",
       "      true_Sheldon  \n",
       "40354        Other  \n",
       "40355        Other  \n",
       "40356        Other  \n",
       "40357        Other  \n",
       "40358        Other  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.78\n"
     ]
    }
   ],
   "source": [
    "accruacy = (test_df.pred_Sheldon == test_df.true_Sheldon).mean()\n",
    "print(f'Accuracy: {accruacy:.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('ada')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "535adef2246893f336cffff7ecb8b5976b9bc4ae850dd312d30c713b14d02600"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
