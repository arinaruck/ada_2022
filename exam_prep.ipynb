{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "SCIPER = 330939"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def train_lr(X_train, X_test, y_train, y_test):\n",
    "    model = LogisticRegression(random_state=42, max_iter=10000)\n",
    "    params = [{'C': [1, 10, 100]}]\n",
    "    model_cv = GridSearchCV(model, params, cv=3, )\n",
    "    model_cv.fit(X_train, y_train)\n",
    "    print(f'The trained model achievs test acc of: {accuracy_score(y_test, model_cv.predict(X_test)):.2f}')\n",
    "    return model_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from functools import partial \n",
    "\n",
    "def bootstrap_CI(data, nbr_draws, interval):\n",
    "\n",
    "    means = np.zeros(nbr_draws)\n",
    "    data = np.array(data)\n",
    "\n",
    "    for n in range(nbr_draws):\n",
    "        indices = np.random.randint(0, len(data), len(data))\n",
    "        data_tmp = data[indices] \n",
    "        means[n] = np.nanmean(data_tmp)\n",
    "\n",
    "    margin = (100 - interval) / 2\n",
    "    return [np.nanpercentile(means, margin),np.nanpercentile(means, 100 - margin)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Networx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a graph\n",
    "\n",
    "edge_list = ...\n",
    "G = nx.DiGraph()\n",
    "G.add_edges_from(edge_list)\n",
    "\n",
    "g_tags_adj = np.loadtxt(open('data/g_tags_adj.csv', 'r'), delimiter=',', skiprows=0)\n",
    "g_tags = nx.from_numpy_array(g_tags_adj)\n",
    "\n",
    "\n",
    "import csv\n",
    "G = nx.MultiDiGraph()\n",
    "\n",
    "with open(\"data/part-1/nodelist.tsv\", \"r\") as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter='\\t')\n",
    "    # This skips the first row of the CSV file.\n",
    "    next(reader)\n",
    "\n",
    "    for u, score, name in reader:\n",
    "       G.add_node(u, score=score, name=name) \n",
    "\n",
    "with open(\"data/part-1/edgelist.tsv\", \"r\") as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter='\\t')\n",
    "    # This skips the first row of the CSV file.\n",
    "    next(reader)\n",
    "\n",
    "    for u, v, gender in reader:\n",
    "       G.add_edge(u, v, gender=gender) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# properties\n",
    "\n",
    "nodes = G.nodes()\n",
    "edges = G.edges()\n",
    "\n",
    "node_id = 1\n",
    "#in/out degree for directed\n",
    "G.in_degree(node_id)\n",
    "# for undirected\n",
    "G.degree(node_id)\n",
    "\n",
    "nx.diameter(G)\n",
    "\n",
    "#connectivity \n",
    "# for directed\n",
    "nx.is_weakly_connected(G)\n",
    "nx.is_strongly_connected(G)\n",
    "# for undirected\n",
    "nx.is_connected(G)\n",
    "\n",
    "sub_nodes = nodes[:10]\n",
    "subgraph = G.subgraph(sub_nodes)\n",
    "\n",
    "index_to_cat = {1: 'cat1', 2: 'cat2'}\n",
    "nx.set_node_attributes(G, index_to_cat, \"category\")\n",
    "\n",
    "\n",
    "centralities = nx.eigenvector_centrality(G) # nx.degree_centrality(G), nx.betweenness_centrality(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting\n",
    "\n",
    "colors = {'Howto & Style': 'pink', 'Gaming': 'green'}\n",
    "\n",
    "list_nodes =list(G.nodes())\n",
    "list_nodes.reverse()   # for showing the nodes with high betweeness centrality \n",
    "pos = nx.spring_layout(G)\n",
    "ec = nx.draw_networkx_edges(G, pos, alpha=0.1)\n",
    "nc = nx.draw_networkx_nodes(G, pos, nodelist=list_nodes, node_color=[colors[G.nodes[n][\"category\"]] for n in list_nodes], \n",
    "                            alpha=0.8, node_shape = '.')\n",
    "plt.colorbar(nc)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "def plot_degree_distribution(G, type):\n",
    "    degrees = [G.in_degree(node) if type == 'in_degree' else G.out_degree(node) for node in G.nodes()]\n",
    "    plt.figure(figsize=(15, 7))\n",
    "    plt.hist(degrees, bins=50)\n",
    "    plt.title(\"Degree Distribution\")\n",
    "    plt.xscale('log')\n",
    "    plt.yscale('log')\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.xlabel(\"Degree\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stat tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assuming the data is distributed normally, to compare the means of the two samples\n",
    "alpha = 0.05\n",
    "\n",
    "df = ...\n",
    "stat, p_val = stats.ttest_ind(df['A'], df['B'], equal_var=False, alternative='less')\n",
    "\n",
    "if p_val < alpha:\n",
    "      print(f'Based on the independent t-test the distribution of the female ranks', \n",
    "            f'the distribution of the male ranks (p value: {p_val:.5f})', sep='')\n",
    "else:\n",
    "      print(f'Based on the independent t-test the distribution the samples come from the same distribution (p value: {p_val:.5f})')\n",
    "\n",
    "# with a plot\n",
    "sns.barplot(df, x='gender', y='ranking', estimator='mean', errorbar=('ci', 95))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ...\n",
    "\n",
    "sns.barplot(\n",
    "    data=df, x=\"high_in_degree\", y=\"finished\", estimator='mean',\n",
    "    errorbar=(\"ci\", 95), capsize=.01, linewidth=0.1,\n",
    ")\n",
    "\n",
    "\n",
    "# heatmap\n",
    "ax = sns.heatmap(inter_rank_hires / inter_rank_hires.sum(axis=1).reshape(-1, 1), annot=True, yticklabels=range(n_cats), xticklabels=range(n_cats))\n",
    "ax.set_xlabel('hired university rank')\n",
    "ax.set_ylabel('graduated university rank');\n",
    "\n",
    "#annotated scatter\n",
    "\n",
    "plt.scatter(share_of_women, score_gain)\n",
    "for i in range(n_cats):\n",
    "    plt.annotate(f'Q{i+1}', (share_of_women[i], score_gain[i] + 0.2))\n",
    "plt.xlabel('share of women')\n",
    "plt.ylabel('mean score gain')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Causality\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answering C2.2** \n",
    "In C1, we are not measuring the direct effect, but the total effect, including the effect mediated through the shortest path length. \n",
    "\n",
    "Possible answers: <br>\n",
    "a) C1 is a very naive analysis, could come up with any confounder that could reverse the effect. <br>\n",
    "b) Depending on on the strength and the sign of the mediated impact, since we are measuring the total impact, we could see different results compared to the true direct causal effect.\n",
    "\n",
    "After matching on source page and shortest path, games with high in-degree source are 14.74% more likely to be finished\n",
    "2. **C3.3:** These differences are smaller compared to how they were before matching, meaning that a lot of the difference can be explained with the mediation through source and the shortest path. However, the direct effect of target in-degree is still significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exact matching\n",
    "\n",
    "game_groups = df.groupby(by=['source', 'shortest_path_length'])\n",
    "\n",
    "matched_groups = []\n",
    "pairs_matched = 0\n",
    "for _, group in game_groups:\n",
    "    high_in_degree_group = group[group['high_in_degree'] == True]\n",
    "    low_in_degree_group = group[group['high_in_degree'] == False]\n",
    "    match_size = min(len(high_in_degree_group), len(low_in_degree_group))\n",
    "    pairs_matched += match_size\n",
    "    matched_groups.append(high_in_degree_group.sample(match_size))\n",
    "    matched_groups.append(low_in_degree_group.sample(match_size))\n",
    "\n",
    "games_matched = pd.concat(matched_groups)\n",
    "\n",
    "print(f'Pairs matched: {pairs_matched}, data points discarded: {len(df) - len(games_matched)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# Declares the model\n",
    "mod = smf.ols(formula='score_gains ~ C(is_female) + src_scores', data=df)\n",
    "# Adding a random seed for consistency\n",
    "#np.random.seed(SEED)\n",
    "res = mod.fit()\n",
    "\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from scipy.stats import spearmanr, pearsonr\n",
    "\n",
    "corr, p_val = spearmanr(questions['ranking'], questions['similarity'])\n",
    "print(f\"Spearman's correlation is: {corr:.3f}\")\n",
    "\n",
    "corr, p_val = pearsonr(questions['ranking'], questions['similarity'])\n",
    "print(f\"Pearson's correlation is: {corr:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5c7b89af1651d0b8571dde13640ecdccf7d5a6204171d6ab33e7c296e100e08a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
