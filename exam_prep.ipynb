{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def train_lr(X_train, X_test, y_train, y_test):\n",
    "    model = LogisticRegression(random_state=42, max_iter=10000)\n",
    "    params = [{'C': [1, 10, 100]}]\n",
    "    model_cv = GridSearchCV(model, params, cv=3, )\n",
    "    model_cv.fit(X_train, y_train)\n",
    "    print(f'The trained model achievs test acc of: {accuracy_score(y_test, model_cv.predict(X_test)):.2f}')\n",
    "    return model_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.11.0 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3.11 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from functools import partial \n",
    "\n",
    "def bootstrap_CI(data, nbr_draws, interval):\n",
    "\n",
    "    means = np.zeros(nbr_draws)\n",
    "    data = np.array(data)\n",
    "\n",
    "    for n in range(nbr_draws):\n",
    "        indices = np.random.randint(0, len(data), len(data))\n",
    "        data_tmp = data[indices] \n",
    "        means[n] = np.nanmean(data_tmp)\n",
    "\n",
    "    margin = (100 - interval) / 2\n",
    "    return [np.nanpercentile(means, margin),np.nanpercentile(means, 100 - margin)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Networx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a graph\n",
    "\n",
    "edge_list = ...\n",
    "G = nx.DiGraph()\n",
    "G.add_edges_from(edge_list)\n",
    "\n",
    "g_tags_adj = np.loadtxt(open('data/g_tags_adj.csv', 'r'), delimiter=',', skiprows=0)\n",
    "g_tags = nx.from_numpy_array(g_tags_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# properties\n",
    "\n",
    "nodes = G.nodes()\n",
    "edges = G.edges()\n",
    "\n",
    "node_id = 1\n",
    "#in/out degree for directed\n",
    "G.in_degree(node_id)\n",
    "# for undirected\n",
    "G.degree(node_id)\n",
    "\n",
    "nx.diameter(G)\n",
    "\n",
    "#connectivity \n",
    "# for directed\n",
    "nx.is_weakly_connected(G)\n",
    "nx.is_strongly_connected(G)\n",
    "# for undirected\n",
    "nx.is_connected(G)\n",
    "\n",
    "sub_nodes = nodes[:10]\n",
    "subgraph = G.subgraph(sub_nodes)\n",
    "\n",
    "index_to_cat = {1: 'cat1', 2: 'cat2'}\n",
    "nx.set_node_attributes(G, index_to_cat, \"category\")\n",
    "\n",
    "\n",
    "centralities = nx.eigenvector_centrality(G) # nx.degree_centrality(G), nx.betweenness_centrality(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting\n",
    "\n",
    "colors = {'Howto & Style': 'pink', 'Gaming': 'green'}\n",
    "\n",
    "list_nodes =list(G.nodes())\n",
    "list_nodes.reverse()   # for showing the nodes with high betweeness centrality \n",
    "pos = nx.spring_layout(G)\n",
    "ec = nx.draw_networkx_edges(G, pos, alpha=0.1)\n",
    "nc = nx.draw_networkx_nodes(G, pos, nodelist=list_nodes, node_color=[colors[G.nodes[n][\"category\"]] for n in list_nodes], \n",
    "                            alpha=0.8, node_shape = '.')\n",
    "plt.colorbar(nc)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "def plot_degree_distribution(G, type):\n",
    "    degrees = [G.in_degree(node) if type == 'in_degree' else G.out_degree(node) for node in G.nodes()]\n",
    "    plt.figure(figsize=(15, 7))\n",
    "    plt.hist(degrees, bins=50)\n",
    "    plt.title(\"Degree Distribution\")\n",
    "    plt.xscale('log')\n",
    "    plt.yscale('log')\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.xlabel(\"Degree\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stat tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assuming the data is distributed normally, to compare the means of the two samples\n",
    "alpha = 0.05\n",
    "\n",
    "df = ...\n",
    "stat, p_val = stats.ttest_ind(df['A'], df['B'], equal_var=False, alternative='less')\n",
    "\n",
    "if p_val < alpha:\n",
    "      print(f'Based on the independent t-test the distribution of the regular attack of A is different from ', \n",
    "            f'the distribution of the regular attack of B', sep='')\n",
    "else:\n",
    "      print('Based on the independent t-test the distribution the samples come from the same distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ...\n",
    "\n",
    "sns.barplot(\n",
    "    data=df, x=\"high_in_degree\", y=\"finished\", estimator='mean',\n",
    "    errorbar=(\"ci\", 95), capsize=.01, linewidth=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Causality\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answering C2.2** \n",
    "In C1, we are not measuring the direct effect, but the total effect, including the effect mediated through the shortest path length. \n",
    "\n",
    "Possible answers: <br>\n",
    "a) C1 is a very naive analysis, could come up with any confounder that could reverse the effect. <br>\n",
    "b) Depending on on the strength and the sign of the mediated impact, since we are measuring the total impact, we could see different results compared to the true direct causal effect.\n",
    "\n",
    "After matching on source page and shortest path, games with high in-degree source are 14.74% more likely to be finished\n",
    "2. **C3.3:** These differences are smaller compared to how they were before matching, meaning that a lot of the difference can be explained with the mediation through source and the shortest path. However, the direct effect of target in-degree is still significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exact matching\n",
    "\n",
    "game_groups = df.groupby(by=['source', 'shortest_path_length'])\n",
    "\n",
    "matched_groups = []\n",
    "pairs_matched = 0\n",
    "for _, group in game_groups:\n",
    "    high_in_degree_group = group[group['high_in_degree'] == True]\n",
    "    low_in_degree_group = group[group['high_in_degree'] == False]\n",
    "    match_size = min(len(high_in_degree_group), len(low_in_degree_group))\n",
    "    pairs_matched += match_size\n",
    "    matched_groups.append(high_in_degree_group.sample(match_size))\n",
    "    matched_groups.append(low_in_degree_group.sample(match_size))\n",
    "\n",
    "games_matched = pd.concat(matched_groups)\n",
    "\n",
    "print(f'Pairs matched: {pairs_matched}, data points discarded: {len(df) - len(games_matched)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5c7b89af1651d0b8571dde13640ecdccf7d5a6204171d6ab33e7c296e100e08a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
